{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbc4c0ca-c995-4cc1-992a-a3ba17b34245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import typing\n",
    "    \n",
    "def make_values_list(values, types=(str, bool, int, float)):\n",
    "    \"\"\"Transform layer type to be sure a list of values is returned.\"\"\"\n",
    "    if type(values) == list:\n",
    "        return values\n",
    "    if type(values) == tuple:\n",
    "        return list(values)\n",
    "    elif type(values)==dict:\n",
    "        return list(values.values())\n",
    "    elif type(values) in types:\n",
    "        return [values]\n",
    "    else:\n",
    "        raise TypeError('Layer name(s) {} should be given through a {},'.format(values, types)+\\\n",
    "                        'a list, or a dictionary(where the key would be the file_paths)')\n",
    "\n",
    "\n",
    "def group_per_layer(\n",
    "        multiplex_list\n",
    "        ):\n",
    "    \"\"\"Group multiplex info per layer.\n",
    "\n",
    "    Structure returned:\n",
    "    {multiplex1: [layer1, layer2, ...],\n",
    "     multiplex2: [layer1, layer2, ...]}\n",
    "\n",
    "    \"\"\"\n",
    "    print(multiplex_list)\n",
    "    multiplex_organised = dict()\n",
    "    for multiplex_name in multiplex_list:\n",
    "        # we instanciata a dict for each multiplex network\n",
    "        multiplex_organised[multiplex_name] = dict()\n",
    "        # we add the layer names\n",
    "        multiplex_organised[multiplex_name]['layers'] =\\\n",
    "            [layer for layer in multiplex_list[multiplex_name]]\n",
    "        # we add the graph type\n",
    "        multiplex_organised[multiplex_name]['graph_type'] =\\\n",
    "            [multiplex_list[multiplex_name][layer] for layer in multiplex_list[multiplex_name]]\n",
    "    return multiplex_organised\n",
    "\n",
    "\n",
    "def save_config(config, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "\n",
    "def setup_proba_config(\n",
    "        config: dict,\n",
    "        eta: list[float],\n",
    "        lamb: list[list[float]]):\n",
    "    \"\"\" Setup the RWR probability for the exploration of hummus networks\n",
    "    with the given eta and lambda values. \"\"\"\n",
    "\n",
    "    assert len(config['multiplex']) == len(eta),\\\n",
    "    'eta (length of {}) should be the same length as the number of layers ({})'\\\n",
    "        .format(len(eta), len(config['multiplex']))\n",
    "    \n",
    "    lamb = lamb.div(lamb.sum(axis=1), axis=0)\n",
    "    config['eta'] = eta\n",
    "    config['lambda'] = lamb.values.tolist()\n",
    "\n",
    "    return config\n",
    "\n",
    "# multilayer_f = '../../flattened_networks/ML_hESC_Chen_GeneNW_all_Peaks2Genes_UP0.5K_DOWN0.5K_nofilt_nofilt_TFlayer_nolinks'\n",
    "# define_grn(multilayer_f, njobs=45)\n",
    "def get_max_lamb(config):\n",
    "    #get layer names connected by bipartites\n",
    "    positions_bipartites = [(config['bipartite'][bipartite]['source'], config['bipartite'][bipartite]['target'])\\\n",
    "                            for bipartite in config['bipartite']]\n",
    "\n",
    "    #create an empty dataframe with layer names that we'll fill where it's possible to be connected according to the bipartites\n",
    "    max_lamb = pd.DataFrame(np.zeros((3,3)),\n",
    "                            index = config['multiplex'].keys(),\n",
    "                            columns = config['multiplex'].keys())\n",
    "\n",
    "    # fill each position corresponding to bipartite\n",
    "    for position in positions_bipartites:\n",
    "        print(position[0], '<-->', position[1])\n",
    "        max_lamb.loc[position] = 1\n",
    "    # ( since we can inverse source and target layers)\n",
    "    #could be conditionned by bipartite directionality\n",
    "    max_lamb+=max_lamb.transpose()\n",
    "    # filling the diagonal to allow intra-layer exploration\n",
    "    max_lamb+=np.eye(3).astype(int)\n",
    "    max_lamb = max_lamb.div(max_lamb.sum(axis=1), axis=0)\n",
    "\n",
    "    \n",
    "    return max_lamb\n",
    "\n",
    "\n",
    "def check_lamb(lamb, config):\n",
    "    \n",
    "    max_lamb = (get_max_lamb(config)>0).astype(int)\n",
    "    \n",
    "    X = np.sum(np.sum((max_lamb - lamb)<0))\n",
    "    if X>0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "def draw_lamb(df):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    G=nx.from_pandas_adjacency(df, create_using=nx.DiGraph())\n",
    "    pos = {list(G.nodes)[-i-1]:np.array((0, i)) for i in range(-len(G.nodes), 0)}\n",
    "    print(list(pos.values())[0][1]-0.5, list(pos.values())[-1][1]+0.5 )\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx(G, with_labels=True, pos = pos,\n",
    "                    node_size=1500, width=4, alpha=0.8, font_weight=\"bold\", arrows=True,\n",
    "                    connectionstyle='arc3, rad = 0.8')\n",
    "\n",
    "    edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "    edge_labels = {k: round(v, 2) for k,v in edge_labels.items()}\n",
    "    print(edge_labels)\n",
    "    self_edges = {}\n",
    "    non_self_edges = {}\n",
    "    for edge in edge_labels.keys():\n",
    "        if edge[0]==edge[1]:\n",
    "            self_edges[edge] = edge_labels[edge]\n",
    "        else:\n",
    "            non_self_edges[edge] = edge_labels[edge]\n",
    "\n",
    "\n",
    "    pos_self_labels = {k:np.array([0, pos[k][1]+0.30]) for k in pos}\n",
    "    my_draw_networkx_edge_labels(G, \n",
    "                                 pos_self_labels, \n",
    "                                 edge_labels=self_edges, \n",
    "                                 font_color='k', \n",
    "                                 font_size = 12, \n",
    "                                 label_pos=12, \n",
    "                                 rad = 0.8,\n",
    "                                 rotate = False)\n",
    "    \n",
    "    my_draw_networkx_edge_labels(G, \n",
    "                                 pos, \n",
    "                                 edge_labels=non_self_edges, \n",
    "                                 font_color='k', \n",
    "                                 font_size = 12, \n",
    "                                 label_pos=0, \n",
    "                                 rad = 0.6,\n",
    "                                 rotate = False)\n",
    "    \n",
    "    ax.set_ylim([list(pos.values())[0][1]-0.5,\n",
    "                 list(pos.values())[-1][1]+0.5 ])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def my_draw_networkx_edge_labels(\n",
    "    G,\n",
    "    pos,\n",
    "    edge_labels=None,\n",
    "    label_pos=0.5,\n",
    "    font_size=10,\n",
    "    font_color=\"k\",\n",
    "    font_family=\"sans-serif\",\n",
    "    font_weight=\"normal\",\n",
    "    alpha=None,\n",
    "    bbox=None,\n",
    "    horizontalalignment=\"center\",\n",
    "    verticalalignment=\"center\",\n",
    "    ax=None,\n",
    "    rotate=True,\n",
    "    clip_on=True,\n",
    "    rad=0\n",
    "):\n",
    "    \"\"\"Draw edge labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : graph\n",
    "        A networkx graph\n",
    "\n",
    "    pos : dictionary\n",
    "        A dictionary with nodes as keys and positions as values.\n",
    "        Positions should be sequences of length 2.\n",
    "\n",
    "    edge_labels : dictionary (default={})\n",
    "        Edge labels in a dictionary of labels keyed by edge two-tuple.\n",
    "        Only labels for the keys in the dictionary are drawn.\n",
    "\n",
    "    label_pos : float (default=0.5)\n",
    "        Position of edge label along edge (0=head, 0.5=center, 1=tail)\n",
    "\n",
    "    font_size : int (default=10)\n",
    "        Font size for text labels\n",
    "\n",
    "    font_color : string (default='k' black)\n",
    "        Font color string\n",
    "\n",
    "    font_weight : string (default='normal')\n",
    "        Font weight\n",
    "\n",
    "    font_family : string (default='sans-serif')\n",
    "        Font family\n",
    "\n",
    "    alpha : float or None (default=None)\n",
    "        The text transparency\n",
    "\n",
    "    bbox : Matplotlib bbox, optional\n",
    "        Specify text box properties (e.g. shape, color etc.) for edge labels.\n",
    "        Default is {boxstyle='round', ec=(1.0, 1.0, 1.0), fc=(1.0, 1.0, 1.0)}.\n",
    "\n",
    "    horizontalalignment : string (default='center')\n",
    "        Horizontal alignment {'center', 'right', 'left'}\n",
    "\n",
    "    verticalalignment : string (default='center')\n",
    "        Vertical alignment {'center', 'top', 'bottom', 'baseline', 'center_baseline'}\n",
    "\n",
    "    ax : Matplotlib Axes object, optional\n",
    "        Draw the graph in the specified Matplotlib axes.\n",
    "\n",
    "    rotate : bool (deafult=True)\n",
    "        Rotate edge labels to lie parallel to edges\n",
    "\n",
    "    clip_on : bool (default=True)\n",
    "        Turn on clipping of edge labels at axis boundaries\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        `dict` of labels keyed by edge\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> G = nx.dodecahedral_graph()\n",
    "    >>> edge_labels = nx.draw_networkx_edge_labels(G, pos=nx.spring_layout(G))\n",
    "\n",
    "    Also see the NetworkX drawing examples at\n",
    "    https://networkx.org/documentation/latest/auto_examples/index.html\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    draw\n",
    "    draw_networkx\n",
    "    draw_networkx_nodes\n",
    "    draw_networkx_edges\n",
    "    draw_networkx_labels\n",
    "    \"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if edge_labels is None:\n",
    "        labels = {(u, v): d for u, v, d in G.edges(data=True)}\n",
    "    else:\n",
    "        labels = edge_labels\n",
    "    text_items = {}\n",
    "    for (n1, n2), label in labels.items():\n",
    "        (x1, y1) = pos[n1]\n",
    "        (x2, y2) = pos[n2]\n",
    "        (x, y) = (\n",
    "            x1 * label_pos + x2 * (1.0 - label_pos),\n",
    "            y1 * label_pos + y2 * (1.0 - label_pos),\n",
    "        )\n",
    "        pos_1 = ax.transData.transform(np.array(pos[n1]))\n",
    "        pos_2 = ax.transData.transform(np.array(pos[n2]))\n",
    "        linear_mid = 0.5*pos_1 + 0.5*pos_2\n",
    "        d_pos = pos_2 - pos_1\n",
    "        rotation_matrix = np.array([(0,1), (-1,0)])\n",
    "        ctrl_1 = linear_mid + rad*rotation_matrix@d_pos\n",
    "        ctrl_mid_1 = 0.5*pos_1 + 0.5*ctrl_1\n",
    "        ctrl_mid_2 = 0.5*pos_2 + 0.5*ctrl_1\n",
    "        bezier_mid = 0.5*ctrl_mid_1 + 0.5*ctrl_mid_2\n",
    "        (x, y) = ax.transData.inverted().transform(bezier_mid)\n",
    "\n",
    "        if rotate:\n",
    "            # in degrees\n",
    "            angle = np.arctan2(y2 - y1, x2 - x1) / (2.0 * np.pi) * 360\n",
    "            # make label orientation \"right-side-up\"\n",
    "            if angle > 90:\n",
    "                angle -= 180\n",
    "            if angle < -90:\n",
    "                angle += 180\n",
    "            # transform data coordinate angle to screen coordinate angle\n",
    "            xy = np.array((x, y))\n",
    "            trans_angle = ax.transData.transform_angles(\n",
    "                np.array((angle,)), xy.reshape((1, 2))\n",
    "            )[0]\n",
    "        else:\n",
    "            trans_angle = 0.0\n",
    "        # use default box of white with white border\n",
    "        if bbox is None:\n",
    "            bbox = dict(boxstyle=\"round\", ec=(1.0, 1.0, 1.0), fc=(1.0, 1.0, 1.0))\n",
    "        if not isinstance(label, str):\n",
    "            label = str(label)  # this makes \"1\" and 1 labeled the same\n",
    "\n",
    "        t = ax.text(\n",
    "            x,\n",
    "            y,\n",
    "            label,\n",
    "            size=font_size,\n",
    "            color=font_color,\n",
    "            family=font_family,\n",
    "            weight=font_weight,\n",
    "            alpha=alpha,\n",
    "            horizontalalignment=horizontalalignment,\n",
    "            verticalalignment=verticalalignment,\n",
    "            rotation=trans_angle,\n",
    "            transform=ax.transData,\n",
    "            bbox=bbox,\n",
    "            zorder=1,\n",
    "            clip_on=clip_on,\n",
    "        )\n",
    "        text_items[(n1, n2)] = t\n",
    "\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False,\n",
    "    )\n",
    "\n",
    "    return text_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bb4b9-a29f-4620-b9f9-fbc812faaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_config(\n",
    "        multiplexes: dict[dict[str]],\n",
    "        bipartites: typing.Union[str, list[str], dict[str]],\n",
    "        seed_path: str = 'seeds/seeds.txt',\n",
    "        folder_multiplexes='multiplex',\n",
    "        folder_bipartites='bipartite',\n",
    "        self_loops=0,\n",
    "        restart_prob=0.7,\n",
    "        bipartites_type: typing.Union[str, list[str], dict[str]] = ['00', '00']\n",
    "        ):\n",
    "\n",
    "    \"\"\"Create a very general config file for the hummus pipeline.\"\"\"\n",
    "    config = dict()\n",
    "    config['multiplex'] = dict()\n",
    "    config['bipartite'] = dict()\n",
    "    config['seed'] = seed_path\n",
    "    config['self_loops'] = self_loops\n",
    "\n",
    "    # We add the multiplexes to the config\n",
    "    for multiplex_name in multiplexes:\n",
    "        print('multiplex_name', multiplex_name)\n",
    "        # If folder_multiplexes is None, use the multiplex name as folder name\n",
    "        config['multiplex'][multiplex_name] = dict()\n",
    "        \n",
    "        config['multiplex'][multiplex_name]['layers'] =\\\n",
    "            [(folder_multiplexes+'/'+multiplex_name+'/'+layer).replace('//',\n",
    "                                                                       '/')\n",
    "             for layer in multiplexes[multiplex_name]['layers']]\n",
    "        for layer in multiplexes[multiplex_name]['layers']:\n",
    "            print('layer', layer)\n",
    "        config['multiplex'][multiplex_name]['graph_type'] =\\\n",
    "            multiplexes[multiplex_name]['graph_type']\n",
    "\n",
    "    # if type of bipartites not associated to their names already,\n",
    "    # we create a dict with the same order as the bipartites\n",
    "    bipartites_type = make_values_list(bipartites_type)\n",
    "    if type(bipartites_type) == list:\n",
    "        temp = dict()\n",
    "        for i in range(len(bipartites)):\n",
    "            temp[list(bipartites.keys())[i]] = bipartites_type[i]\n",
    "        bipartites_type = temp\n",
    "\n",
    "    # we add the bipartites\n",
    "    print(type(bipartites_type))\n",
    "    for bipartite in bipartites:\n",
    "        bipartite_loc = folder_bipartites+'/'+bipartite\n",
    "        config['bipartite'][bipartite_loc] = dict()\n",
    "        config['bipartite'][bipartite_loc]['source'] = \\\n",
    "            bipartites[bipartite]['multiplex_left']\n",
    "        config['bipartite'][bipartite_loc]['target'] = \\\n",
    "            bipartites[bipartite]['multiplex_right']\n",
    "        config['bipartite'][bipartite_loc]['graph_type'] = \\\n",
    "            bipartites_type[bipartite]\n",
    "\n",
    "    config['r'] = restart_prob\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ad153-e73a-4a44-92db-e44d9af4443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list = {'TF': {'TF_network': '00'}, 'RNA': {'RNA_GENIE3': '10'}, 'peaks': {'peak_network_cicero': '10'}}\n",
    "m_list = group_per_layer(m_list)\n",
    "\n",
    "         {'TF': {'TF_network': '00'}, 'RNA': {'RNA_GENIE3': '10'}, 'peaks': {'peak_network_cicero': '10'}}\n",
    "b_list = {'atac_rna':{'multiplex_right' : 'peaks', 'multiplex_left' :'RNA'},\n",
    "        'tf_peak' : {'multiplex_right' : \"TF_network\", 'multiplex_left': \"peaks\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed023d-dd9b-4883-87db-da18e2ba00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be4be5-9df3-4ec2-be2c-a051b5ff2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_config(m_list, b_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef052fd-0eb9-48bd-b727-55284966267f",
   "metadata": {},
   "source": [
    "#### Lamb related checking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a62b6-0891-416b-8e32-8611a24054b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_lamb(lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd6434-8527-44a4-a789-a718012b7399",
   "metadata": {},
   "source": [
    "#### Random walks functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4333c55-4fab-4d25-aa07-378680b6a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiple_RandomWalk(\n",
    "    multilayer_f,\n",
    "    config_name,\n",
    "    output_f,\n",
    "    list_seeds,\n",
    "    config_folder='config',\n",
    "    save=True,\n",
    "    return_df=False,\n",
    "    spec_layer_result_saved='all',\n",
    "    njobs=1):\n",
    "\n",
    "    ranking_all_dfs = pd.DataFrame(columns = ['layer', 'target', 'path_layer', 'score', 'seed'])\n",
    "\n",
    "    l_ranking_df = Parallel(n_jobs=njobs)(delayed(compute_RandomWalk)(multilayer_f, config_name, seeds, config_folder, spec_layer_result_saved)\\\n",
    "                                                                          for seeds in tqdm(list_seeds,\n",
    "                                                                                            position = 0, \n",
    "                                                                                           leave = True))\n",
    "    ranking_all_dfs = pd.concat([ranking_all_dfs]+l_ranking_df)\n",
    "    ranking_all_dfs = ranking_all_dfs.sort_values(by='score')\n",
    "\n",
    "    if save:\n",
    "        assert output_f!=None, 'You need to provide an output_f name to save the random walks result'\n",
    "        ranking_all_dfs.to_csv(output_f, sep='\\t', index=False, header=True)\n",
    "    if return_df:\n",
    "        return ranking_all_dfs\n",
    "\n",
    "def compute_RandomWalk(\n",
    "    multilayer_f,\n",
    "    config_name,\n",
    "    seeds,\n",
    "    config_folder='config',\n",
    "    spec_layer_result_saved='all',\n",
    "    unnamed=False,\n",
    "    njobs=1):\n",
    "\n",
    "    # seeds file names\n",
    "    seeds = make_values_list(seeds)\n",
    "    if unnamed is True:\n",
    "        seeds_filename = 'seeds.txt'\n",
    "        if njobs>1:\n",
    "            raise Exception(\"Impossible to use unnamed seeds files while parallelising random walks.\")\n",
    "    else:\n",
    "        seeds_filename = '_'.join(seeds)\n",
    "\n",
    "    # write seeds file\n",
    "    with open(multilayer_f+'/seeds/'+seeds_filename+'.txt', 'w') as f:\n",
    "        f.write('\\n'.join(seeds)+'\\n')        \n",
    "    \n",
    "    # config file personalised with seed file\n",
    "    with open(multilayer_f+'/{}/'.format(config_folder)+config_name, 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.BaseLoader)\n",
    "        config['seed'] = 'seeds/'+seeds_filename+'.txt'\n",
    "    with open(multilayer_f+'/{}/'.format(config_folder)+seeds_filename+'_'+config_name, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "        \n",
    "    # multixrank\n",
    "    multixrank_obj = mxr.Multixrank(config=multilayer_f+'/{}/'.format(config_folder)+seeds_filename+'_'+config_name, wdir=multilayer_f)\n",
    "    ranking_df = multixrank_obj.random_walk_rank()\n",
    "    \n",
    "    # and filter df results andadd seeds name\n",
    "    ranking_df['tf'] = '_'.join(seeds)\n",
    "    ranking_df = ranking_df[ranking_df.score > 0]  # ??\n",
    "    ranking_df.columns = ['layer', 'target', 'path_layer', 'score', 'seed']\n",
    "    if spec_layer_result_saved != 'all':\n",
    "        if type(spec_layer_result_saved)==str:\n",
    "            spec_layer_result_saved = [spec_layer_result_saved]\n",
    "        ranking_df = ranking_df[ranking_df['layer'].isin(spec_layer_result_saved)]\n",
    "\n",
    "    return ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b52de-6a43-4da7-b829-6147e3532ca1",
   "metadata": {},
   "source": [
    "#### Probas for classic GRN definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c088f-c475-49a1-a594-29b672ecf417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hummuspy.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8941423-6759-4f90-9a70-a0b3c132442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hummuspy.config.get_classic_grn_lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ba39e-5004-4d01-a5e5-b5ab528d89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classic_grn_lamb(config,\n",
    "                         tf_multiplex='TF',\n",
    "                         peak_multiplex='peaks',\n",
    "                         rna_multiplex='RNA',\n",
    "                         draw=True\n",
    "                        ):\n",
    "    \n",
    "    for multiplex in [tf_multiplex, peak_multiplex, rna_multiplex]:\n",
    "        assert multiplex in config['multiplex'].keys(), 'The multiplex {} is not in the config file provided'.format(multiplex)\n",
    "        \n",
    "    ordered_multiplexes = config['multiplex'].keys()\n",
    "    lamb = pd.DataFrame(np.ones((3,3)),\n",
    "                        index = ordered_multiplexes,\n",
    "                        columns = ordered_multiplexes)\n",
    "    # Remove proba between TF and RNA layers\n",
    "    lamb.loc[tf_multiplex, rna_multiplex] = 0\n",
    "    lamb.loc[rna_multiplex, tf_multiplex] = 0\n",
    "    lamb = lamb.div(lamb.sum(axis=1), axis=0)\n",
    "\n",
    "    # max_lambd check to see\n",
    "    assert check_lamb(config=config, lamb=lamb), 'There seem to be a incoherence between bipartite source/targets and multiplex names provided in get_classic_grn_lamb'\n",
    "    \n",
    "    if draw == True:\n",
    "        to_draw_lamb = lamb.loc[[tf_multiplex, peak_multiplex, rna_multiplex],\n",
    "                                [tf_multiplex, peak_multiplex, rna_multiplex]]\n",
    "        \n",
    "        draw_lamb(to_draw_lamb)\n",
    "        \n",
    "    return lamb\n",
    "\n",
    "\n",
    "def get_classic_grn_eta(config,\n",
    "                        rna_multiplex='RNA'):\n",
    "\n",
    "    ordered_multiplex = config['multiplex'].keys()\n",
    "    assert rna_multiplex in ordered_multiplex, \"It seems rna_multiplex not in config['multiplex']\"\n",
    "\n",
    "    eta = [0 if multiplex!=rna_multiplex else 1 for multiplex in ordered_multiplex ]\n",
    "    return eta\n",
    "\n",
    "\n",
    "def define_grn(\n",
    "    multilayer_f,\n",
    "    config,\n",
    "    gene_list = 'all',\n",
    "    tf_list = 'all',\n",
    "    config_name='grn_config.yml',\n",
    "    config_folder = 'config',\n",
    "    tf_multiplex:str='TF',\n",
    "    peak_multiplex:str='peaks',\n",
    "    rna_multiplex:str='RNA',\n",
    "    update_config=True,\n",
    "    save=False,\n",
    "    return_df=True,\n",
    "    output_f=None,\n",
    "    njobs=1):\n",
    "    \n",
    "    # store mutliplex already because it will be when saving yaml file,\n",
    "    # while eta and lambda won't.\n",
    "    config['multiplex'] = {k:config['multiplex'][k] for k in sorted(config['multiplex'].keys())}\n",
    "    \n",
    "    if update_config:\n",
    "        eta = get_classic_grn_eta(config)\n",
    "        lamb = get_classic_grn_lamb(config, draw=False)\n",
    "        config = setup_proba_config(config, eta, lamb)\n",
    "    config_path = multilayer_f+'/'+config_folder+'/'+config_name\n",
    "    save_config(config, config_path)\n",
    "    \n",
    "    if gene_list == 'all':\n",
    "        gene_list = []\n",
    "        for layer in config['multiplex'][rna_multiplex]['layers']:\n",
    "            df_layer = pd.read_csv(multilayer_f+'/'+layer, sep='\\t', header=None, index_col=None)\n",
    "            layer_nodes = np.concatenate([np.unique(df_layer[0].values),\n",
    "                                          np.unique(df_layer[1].values)])\n",
    "            gene_list = np.unique(np.concatenate([gene_list,\n",
    "                                                layer_nodes]))            \n",
    "\n",
    "    df = compute_multiple_RandomWalk(multilayer_f,\n",
    "                                config_name=config_name,\n",
    "                                output_f=output_f,\n",
    "                                list_seeds = gene_list,\n",
    "                                config_folder=config_folder,\n",
    "                                save=False,\n",
    "                                return_df=return_df,\n",
    "                                spec_layer_result_saved=tf_multiplex,\n",
    "                                njobs=1)\n",
    "\n",
    "    df['gene'] = df['seed']\n",
    "    df['tf'] = df['target']\n",
    "    del df['target']\n",
    "    del df['seed']\n",
    "\n",
    "    if tf_list == 'all':\n",
    "        tf_list = []\n",
    "        for layer in config['multiplex'][tf_multiplex]['layers']:\n",
    "            df_layer = pd.read_csv(multilayer_f+'/'+layer, sep='\\t', header=None, index_col=None)\n",
    "            layer_nodes = np.concatenate([np.unique(df_layer[0].values),\n",
    "                                          np.unique(df_layer[1].values)])\n",
    "            tf_list = np.unique(np.concatenate([tf_list,\n",
    "                                                layer_nodes]))\n",
    "\n",
    "    # Add normalisation ?\n",
    "    df = df[df['tf'].isin(tf_list)]\n",
    "\n",
    "    if save:\n",
    "        assert output_f!=None, 'You need to provide an output_f name to save the GRN result'\n",
    "        ranking_all_dfs.sort_values(by='score').to_csv(output_f, sep='\\t', index=False, header=True)\n",
    "\n",
    "    if return_df:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360f145-324b-4794-a714-d8f85efdadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import yaml\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multixrank as mxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e66a0-e39a-43de-baa4-fa85ba8a4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./a/config.yaml\"\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.BaseLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94f40f-306b-4449-96e5-c59a857a2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['multiplex']['RNA']['graph_type'] = ['10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbd89e-d87c-4329-9293-d9eae90edb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['multiplex']['peaks']['graph_type'] = ['10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce63b5-21c8-4ef3-bc6b-a0b1051fcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "define_grn('a', config, njobs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46413946-9f3f-4de0-ae0a-022e697656f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa2288-77c0-4bcd-9d56-6232640a14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplex_list = {'TF': {'TF_network': '00'}, 'RNA': {'RNA_GENIE3': '00'}, 'peak_network': {'peak_network_GENIE3': '00'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54224acf-be44-4674-a5e9-7c5350618850",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = group_per_layer(multiplex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1cad50-8c04-4987-8fc9-e9da9385f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartites_list = {'RNA_peak' : {'multiplex_right' : 'TF', 'multiplex_left' : 'peak'}, \n",
    "                   'TF_peak' : {'multiplex_right' : 'RNA', 'multiplex_left' : 'peak'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a777b6b-b4e9-475e-95b7-a9f7ae10ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_config(a, bipartites_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3913d77f-497a-4e0f-a141-78c9f4ec0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = get_classic_grn_lamb(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86de89b-fe1b-4b94-8d81-a68fd7d85913",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_lamb(lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9b73a-9219-4f53-b5c0-15a8bd069452",
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartites_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f4a20-59c1-49af-b82f-3eb9d3ad0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multixrank as mxr\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_values_list(values, types=(str, bool, int, float)):\n",
    "    \"\"\"Transform layer type to be sure a list of values is returned.\"\"\"\n",
    "    if type(values) == list:\n",
    "        return values\n",
    "    elif type(values)==dict:\n",
    "        return list(values.values())\n",
    "    elif type(values) in types:\n",
    "        return [values]\n",
    "    else:\n",
    "        raise TypeError('Layer name(s) {} should be given through a {},'.format(values, types)+\\\n",
    "                        'a list, or a dictionary(where the key would be the file_paths)')\n",
    "\n",
    "\n",
    "\n",
    "def detailed_config(\n",
    "    request: str,\n",
    "    filename: str,\n",
    "    tf_layers: typing.Union[str, list[str], dict[str]],\n",
    "    atac_layers: typing.Union[str, list[str], dict[str]],\n",
    "    rna_layers: typing.Union[str, list[str], dict[str]],\n",
    "    tf_atac_links: str, \n",
    "    atac_rna_links: str,\n",
    "    seed_path: str = 'seeds/seeds.txt',\n",
    "    folder_tf_layers = 'layer_TFS',\n",
    "    folder_atac_layers = 'layer_PEAKS',\n",
    "    folder_rna_layers = 'layer_GENES',\n",
    "    tf_layers_weighted: typing.Union[bool, list[bool], dict[bool]] = False, \n",
    "    atac_layers_weighted: typing.Union[bool, list[bool], dict[bool]] = True, \n",
    "    rna_layers_weighted: typing.Union[bool, list[bool], dict[bool]] = True,\n",
    "    tf_layers_directed: typing.Union[bool, list[bool], dict[bool]] = False, \n",
    "    atac_layers_directed: typing.Union[bool, list[bool], dict[bool]] = False, \n",
    "    rna_layers_directed: typing.Union[bool, list[bool], dict[bool]] = False,\n",
    "    tf_atac_links_weighted: bool = False,\n",
    "    atac_rna_links_weighted: bool = False,\n",
    "    tf_atac_links_directed: bool = False, \n",
    "    atac_rna_links_directed: bool = False,\n",
    "    r:float = 0.7,\n",
    "    self_loops = 0, \n",
    "    return_config = False):\n",
    "    \n",
    "    config = define_minimal_config(\n",
    "        tf_layers=tf_layers,\n",
    "        atac_layers=atac_layers,\n",
    "        rna_layers=rna_layers,\n",
    "        tf_atac_links=tf_atac_links, \n",
    "        atac_rna_links=atac_rna_links,\n",
    "        seed_path=seed_path,\n",
    "        folder_tf_layers = folder_tf_layers,\n",
    "        folder_atac_layers = folder_atac_layers,\n",
    "        folder_rna_layers = folder_rna_layers,\n",
    "        tf_layers_weighted=tf_layers_weighted, \n",
    "        atac_layers_weighted=atac_layers_weighted, \n",
    "        rna_layers_weighted=rna_layers_weighted,\n",
    "        tf_layers_directed=tf_layers_directed, \n",
    "        atac_layers_directed=atac_layers_directed, \n",
    "        rna_layers_directed=rna_layers_directed,\n",
    "        tf_atac_links_weighted=tf_atac_links_weighted,\n",
    "        atac_rna_links_weighted=atac_rna_links_weighted,\n",
    "        tf_atac_links_directed=tf_atac_links_directed, \n",
    "        atac_rna_links_directed=atac_rna_links_directed,\n",
    "        r=r,\n",
    "        self_loops = self_loops)\n",
    "    \n",
    "    if request.upper()=='GRN':\n",
    "        layers_eta = [1, 0, 0]\n",
    "        \n",
    "        #Check direction of lamb entry in the last multixrank version !!!\n",
    "        go_to_tfs   = [0, '1/3', 0]\n",
    "        go_to_peaks = [1, '1/3', 0.5]\n",
    "        go_to_genes = [0, '1/3', 0.5]\n",
    "\n",
    "    elif request.enhancers()=='enhancers':\n",
    "        layers_eta = [0, 0, 1]\n",
    "\n",
    "        #Check direction of lamb entry in the last multixrank version !!!\n",
    "        go_to_tfs   = [0, 0, 0]\n",
    "        go_to_peaks = [1, 1, 1]\n",
    "        go_to_genes = [0, 0, 0]\n",
    "\n",
    "    elif request.enhancers()=='target_regions':\n",
    "        layers_eta = [1, 0, 0]\n",
    "\n",
    "        #Check direction of lamb entry in the last multixrank version !!!\n",
    "        go_to_tfs   = [0, 0, 0]\n",
    "        go_to_peaks = [1, 1, 1]\n",
    "        go_to_genes = [0, 0, 0]\n",
    "\n",
    "    layers_proba = [go_to_tfs, go_to_peaks, go_to_genes]\n",
    "    layers_names = [folder_tf_layers, folder_atac_layers, folder_rna_layers]\n",
    "    \n",
    "    #sort transition matrix based on order of layers in the config file, aka alphabetical order\n",
    "    config['lamb'] = [[val for _, val in sorted(zip(layers_names, go_to_proba))]\\\n",
    "                      for _, go_to_proba in sorted(zip(layers_names, layers_proba))]\n",
    "    config['eta']  = [eta for _, eta  in sorted(zip(layers_names, layers_eta))]\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    if return_config:\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9309daa-dbb2-4a49-9027-a4383fffe19e",
   "metadata": {},
   "source": [
    "define_grn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a9fe5e-286a-4135-af00-734ca6aaea2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_grn(\n",
    "    multilayer_f: str,\n",
    "    TFs: typing.Union[str, list[str], dict[str]] = 'all',\n",
    "    save: bool = True,\n",
    "    output_f_grn = 'RW_grn.tsv',\n",
    "    Return: bool = False,\n",
    "    njobs:int = 1,\n",
    "    target_saved: typing.Union['genes', 'peaks', 'tfs'] = 'genes',\n",
    "    tf_layers: typing.Union[str, list[str], dict[str]] = 'tf_edges.tsv',\n",
    "    atac_layers: typing.Union[str, list[str], dict[str]] = 'peak_edges.tsv',\n",
    "    rna_layers: typing.Union[str, list[str], dict[str]] = 'gene_edges.tsv',\n",
    "    tf_atac_links: str = 'bipartite/tfs2peaks.tsv', \n",
    "    atac_rna_links: str = 'bipartite/peaks2genes.tsv',\n",
    "    config_name='grn_config.yml',\n",
    "    config_folder='config',\n",
    "    seed_path: str = 'seeds/seeds.txt',\n",
    "    folder_tf_layers: str = 'multiplex/layer_TFS',\n",
    "    folder_atac_layers: str = 'multiplex/layer_PEAKS',\n",
    "    folder_rna_layers: str = 'multiplex/layer_GENES',\n",
    "    tf_layers_weighted: typing.Union[bool, list[bool], dict[bool]] = False, \n",
    "    atac_layers_weighted: typing.Union[bool, list[bool], dict[bool]] = True, \n",
    "    rna_layers_weighted: typing.Union[bool, list[bool], dict[bool]] = True,\n",
    "    tf_layers_directed: typing.Union[bool, list[bool], dict[bool]] = False, \n",
    "    atac_layers_directed: typing.Union[bool, list[bool], dict[bool]] = False, \n",
    "    rna_layers_directed: typing.Union[bool, list[bool], dict[bool]] = False,\n",
    "    tf_atac_links_weighted: bool = False,\n",
    "    atac_rna_links_weighted: bool = False,\n",
    "    tf_atac_links_directed: bool = False, \n",
    "    atac_rna_links_directed: bool = False,\n",
    "    r:float = 0.7,\n",
    "    self_loops: bool = 0):\n",
    "\n",
    "    detailed_config(\n",
    "        request='grn',\n",
    "        filename=multilayer_f+'/'+config_folder+'/'+config_name,\n",
    "        tf_layers=tf_layers,\n",
    "        atac_layers=atac_layers,\n",
    "        rna_layers=rna_layers,\n",
    "        tf_atac_links=tf_atac_links,\n",
    "        atac_rna_links=atac_rna_links,\n",
    "        seed_path=seed_path,\n",
    "        folder_tf_layers=folder_tf_layers,\n",
    "        folder_atac_layers=folder_atac_layers,\n",
    "        folder_rna_layers=folder_rna_layers,\n",
    "        tf_layers_weighted=tf_layers_weighted,\n",
    "        atac_layers_weighted=atac_layers_weighted,\n",
    "        rna_layers_weighted=rna_layers_weighted,\n",
    "        tf_layers_directed=tf_layers_directed,\n",
    "        atac_layers_directed=atac_layers_directed,\n",
    "        rna_layers_directed=rna_layers_directed,\n",
    "        tf_atac_links_weighted=tf_atac_links_weighted,\n",
    "        atac_rna_links_weighted=atac_rna_links_weighted,\n",
    "        tf_atac_links_directed=tf_atac_links_directed,\n",
    "        atac_rna_links_directed=atac_rna_links_directed,\n",
    "        r=r,\n",
    "        self_loops=self_loops,\n",
    "        return_config=False)\n",
    "    \n",
    "    if TFs == 'all':\n",
    "        TFs = list(pd.read_csv(multilayer_f + '/' + tf_atac_links, sep=\"\\t\", header=None)[0].str.strip().unique())\n",
    "    TFs = make_values_list(TFs)\n",
    "    \n",
    "    rna_layers = make_values_list(rna_layers)\n",
    "    print([folder_rna_layers+'/'+rna_layer for rna_layer in rna_layers])\n",
    "\n",
    "    if Return is True:\n",
    "        grn = compute_multiple_RandomWalk(\n",
    "            multilayer_f=multilayer_f,\n",
    "            config_name=config_name,\n",
    "            output_f=output_f_grn,\n",
    "            list_seeds=TFs,\n",
    "            config_folder=config_folder,\n",
    "            save=save,\n",
    "            Return=Return,\n",
    "            spec_layer_result_saved=folder_rna_layers,\n",
    "            njobs=njobs)\n",
    "        return grn\n",
    "    else:\n",
    "        grn = compute_multiple_RandomWalk(\n",
    "            multilayer_f=multilayer_f,\n",
    "            config_name=config_name,\n",
    "            output_f=output_f_grn,\n",
    "            list_seeds=TFs,\n",
    "            config_folder=config_folder,\n",
    "            save=save,\n",
    "            Return=Return,\n",
    "            spec_layer_result_saved=folder_rna_layers,\n",
    "            njobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380667d4-6d86-4f1c-9e50-af9380ed7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'bipartite': {'bipartite/atac_rna.tsv': {'graph_type': '00',\n",
    "   'source': 'RNA',\n",
    "   'target': 'peaks'},\n",
    "  'bipartite/tf_peak.tsv': {'graph_type': '00',\n",
    "   'source': 'peaks',\n",
    "   'target': 'TF'}},\n",
    " 'eta': ['1', '0', '0'],\n",
    " 'lambda': [['1', '0', '0'], ['1/3', '1/3', '1/3'], ['0', '1/2', '1/2']],\n",
    " 'multiplex': {'TF': {'graph_type': ['00'],\n",
    "   'layers': ['multiplex/TF/TF_network.tsv']},\n",
    "  'RNA': {'graph_type': ['00'], 'layers': ['multiplex/RNA/RNA_GENIE3.tsv']},\n",
    "  'peaks': {'graph_type': ['00'],\n",
    "   'layers': ['multiplex/peaks/peak_network_cicero.tsv']}},\n",
    " 'seed': 'seeds/seeds.txt',\n",
    " 'self_loops': '0'}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad13cc-9d04-44f2-b639-b3a8f13a7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "multixrank_obj = mxr.Multixrank(config=filename, wdir='a')\n",
    "ranking_df = multixrank_obj.random_walk_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78508109-f139-4514-9e7f-b1725d1ea8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76c083-72f9-4ece-b87e-dd7e468ef336",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Errors\n",
    "Graph types of multiplex should be lists\n",
    "\n",
    "No empty tsv file as layers\n",
    "\n",
    "bipartites instead of bipartite in path config bipartites\n",
    "\n",
    "Add .tsv at the end of bipartites path\n",
    "\n",
    "seeds/seed.tsv doesn't exist\n",
    "\n",
    "remove eta and lamb from config file if null cause must be numbers etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc73d6-a1a3-4c77-93eb-ef8396cd085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['multiplex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ccad1-37a6-42b1-ae16-828f6618f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = get_max_lamb(config)\n",
    "lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf185a-40ef-41bb-acbe-0602c1ad0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = get_classic_grn_eta(config)\n",
    "lamb = get_classic_grn_lamb(config, draw=True)\n",
    "config = setup_proba_config(config, eta, lamb)\n",
    "eta, lamb, config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da4f6e-0c15-4c69-8f52-e7a70bf4d589",
   "metadata": {},
   "source": [
    "### Test hummuspy pip version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c58f17-cb49-4d3a-b5bc-2ff92cd9ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hummuspy.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff6b42-bac6-42e3-8ec9-b54334b365ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hummuspy.config.general_config(multiplex_list, bipartites_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff1fa9-0229-48e1-834e-93e6575fb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartites_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de621d-3ab4-4c64-aba0-61f3396d0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_values_list(('00', '00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e8dad-8962-462a-802a-8906f17d4c9d",
   "metadata": {},
   "source": [
    "Copy pasta of config functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ca7c1-fc45-4a5b-9d8f-f9a80881389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = make_values_list('A2M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe8591b-16ba-4b07-ada9-2554c3fda6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplex_list = {'TF': {'TF_network': '00'}, 'RNA': {'RNA_GENIE3': '00'}, 'peaks': {'peak_network_cicero': '00'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bda0e1-8d37-4c34-8304-376ded27a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartites_list = {'atac_rna.tsv' : {'multiplex_right' : 'RNA', 'multiplex_left' : 'peaks'}, \n",
    "                   'tf_peak.tsv' : {'multiplex_right' : 'TF', 'multiplex_left' : 'peaks'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cf29f-374a-4e98-8410-fa6a357acece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = define_grn(\n",
    "    'b',\n",
    "    c,\n",
    "    gene_list=None,\n",
    "    njobs = 8,\n",
    "    draw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ac885d-ff34-43f3-92f8-23e931e25969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b3fb8ec-6fc4-412b-b4e8-51b3a454bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "a = a[a!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7038b46f-3733-4c1e-8f3b-3fd07d2d74bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd43533-18c4-4558-8e6f-b1629e4a5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['gene']=='ARID3A'].score.value_counts(), df[df['gene']=='ARID3A'][df[df['gene']=='ARID3A']['tf']=='fake_node']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06fcaa-268c-4181-9617-142cb0aba18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classic_grn_lamb(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cce84-eb95-4f49-957d-387adcf6aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93efc18-1f19-475f-96bc-b55ad2f631d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartites_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d018e1b7-51e7-4f66-bc0c-0e7b2894e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'multiplex': {'RNA': {'layers': ['multiplex/RNA/RNA_GENIE3.tsv'],\n",
    "   'graph_type': ['00']},\n",
    "  'TF': {'layers': ['multiplex/TF/TF_network.tsv'], 'graph_type': ['00']},\n",
    "  'peaks': {'layers': ['multiplex/peaks/peak_network_GENIE3.tsv'],\n",
    "   'graph_type': ['00']}},\n",
    " 'bipartite': {'bipartite/RNA_peak': {'source': 'peaks',\n",
    "   'target': 'TF',\n",
    "   'graph_type': '00'},\n",
    "  'bipartite/TF_peak': {'source': 'peaks',\n",
    "   'target': 'RNA',\n",
    "   'graph_type': '00'}},\n",
    " 'seed': 'seeds/seeds.txt',\n",
    " 'self_loops': 0,\n",
    " 'r': 0.7,\n",
    " 'eta': [1, 0, 0],\n",
    " 'lambda': [[0.5, 0.0, 0.5],\n",
    "  [0.0, 0.5, 0.5],\n",
    "  [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14ee769-c9f4-42c1-b879-9469e9c47501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hummuspy.explore_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ffc212-6335-4cff-a2b8-8454d43b67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilayer_f = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1493a4d-82c8-45e2-8443-da2ac319f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplexes_list =  {'TF': {'TF_network': '00'}, 'RNA': {'RNA_GENIE3': '10'}, 'peaks': {'peak_network_cicero': '10'}}\n",
    "bipartites_list =  {'atac_rna.tsv': {'multiplex_right': 'peaks', 'multiplex_left': 'RNA'},\n",
    "                    'tf_peak.tsv': {'multiplex_right': 'TF', 'multiplex_left': 'peaks'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9fbc716-3328-4026-a5f1-abc9caed13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grn = hummuspy.explore_network.define_grn_for_R(\n",
    "    multilayer_f,\n",
    "    multiplex_list,\n",
    "    bipartites_list,\n",
    "    tf_multiplex = \"TF\",\n",
    "    peak_multiplex = \"peaks\",\n",
    "    rna_multiplex = \"RNA\",\n",
    "    update_config = True,\n",
    "    njobs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770879a3-a502-409a-bcd4-2715c6f3f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'multiplex': {'RNA': {'layers': ['multiplex/RNA/RNA_GENIE3.tsv'],\n",
    "   'graph_type': ['00']},\n",
    "  'TF': {'layers': ['multiplex/TF/TF_network.tsv'], 'graph_type': ['00']},\n",
    "  'peaks': {'layers': ['multiplex/peaks/peak_network_GENIE3.tsv'],\n",
    "   'graph_type': ['00']}},\n",
    " 'bipartite': {'bipartite/RNA_peak': {'source': 'peaks',\n",
    "   'target': 'TF',\n",
    "   'graph_type': '00'},\n",
    "  'bipartite/TF_peak': {'source': 'peaks',\n",
    "   'target': 'RNA',\n",
    "   'graph_type': '00'}},\n",
    " 'seed': 'seeds/seeds.txt',\n",
    " 'self_loops': 0,\n",
    " 'r': 0.7,\n",
    " 'eta': [1, 0, 0],\n",
    " 'lambda': [[0.5, 0.0, 0.5],\n",
    "  [0.0, 0.5, 0.5],\n",
    "  [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55849967-9a42-49f6-8f63-e1c95eda2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_lamb(config,\n",
    "                    tf_multiplex='TF',\n",
    "                    peak_multiplex='peaks',\n",
    "                    rna_multiplex='RNA',\n",
    "                    value = 1):\n",
    "    \n",
    "    for multiplex in [tf_multiplex, peak_multiplex, rna_multiplex]:\n",
    "        assert multiplex in config['multiplex'].keys(),\\\n",
    "            \"The multiplex {}\".format(multiplex) +\\\n",
    "            \" is not in the config file provided\"\n",
    "\n",
    "    ordered_multiplexes = config['multiplex'].keys()\n",
    "\n",
    "    if value == 1:\n",
    "        array = np.ones((3, 3))\n",
    "    elif value == 0:\n",
    "        array = np.zeros((3,3))\n",
    "    else:\n",
    "        raise ValueError('value param of initialise_lamb should only be 1 or 0')\n",
    "    \n",
    "    lamb = pd.DataFrame(array,\n",
    "                        index=ordered_multiplexes,\n",
    "                        columns=ordered_multiplexes)\n",
    "    return lamb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a05315d-b7d8-4a2a-b6c4-7718ba4a55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Get enhancers classic lamb   #\n",
    "#################################\n",
    "def get_classic_enhancers_lamb(config,\n",
    "                         tf_multiplex='TF',\n",
    "                         peak_multiplex='peaks',\n",
    "                         rna_multiplex='RNA',\n",
    "                         draw=True\n",
    "                         ):\n",
    "\n",
    "    lamb = initialise_lamb(config,\n",
    "                           tf_multiplex,\n",
    "                           peak_multiplex,\n",
    "                           rna_multiplex,\n",
    "                           value=0) # because enhancer lamb is mostly 0s\n",
    "    print(lamb)\n",
    "    \n",
    "    # Remove proba between TF and RNA layers\n",
    "    lamb.loc[peak_multiplex, rna_multiplex] = 1\n",
    "    lamb.loc[peak_multiplex, peak_multiplex] = 1\n",
    "    lamb.loc[rna_multiplex, peak_multiplex] = 1\n",
    "    lamb = lamb.div(lamb.sum(axis=1),\n",
    "                    axis=0)\n",
    "    lamb = lamb.fillna(0)\n",
    "    print(lamb)\n",
    "\n",
    "    # max_lambd check to see\n",
    "    assert check_lamb(config=config, lamb=lamb), \"There seem to be a \" +\\\n",
    "        \"incoherence between bipartite source/targets and multiplex names\" +\\\n",
    "        \"provided in get_classic_grn_lamb\"\n",
    "\n",
    "    if draw is True:\n",
    "        to_draw_lamb = lamb.loc[[tf_multiplex, peak_multiplex, rna_multiplex],\n",
    "                                [tf_multiplex, peak_multiplex, rna_multiplex]]\n",
    "        draw_lamb(to_draw_lamb)\n",
    "\n",
    "    return lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f62547fd-5cae-4ebf-a73b-5a930ce022d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Get binding regions classic lamb   #\n",
    "#################################\n",
    "def get_target_genes_lamb(config,\n",
    "                         tf_multiplex='TF',\n",
    "                         peak_multiplex='peaks',\n",
    "                         rna_multiplex='RNA',\n",
    "                         draw=True\n",
    "                         ):\n",
    "\n",
    "    lamb = initialise_lamb(config,\n",
    "                           tf_multiplex,\n",
    "                           peak_multiplex,\n",
    "                           rna_multiplex,\n",
    "                           value=1) # because enhancer lamb is mostly 0s\n",
    "    print(lamb)\n",
    "    \n",
    "    # Remove proba between TF and RNA layers\n",
    "    lamb.loc[tf_multiplex, rna_multiplex] = 0\n",
    "    lamb.loc[rna_multiplex, tf_multiplex] = 0\n",
    "    lamb = lamb.div(lamb.sum(axis=1),\n",
    "                    axis=0)\n",
    "    lamb = lamb.fillna(0)\n",
    "    print(lamb)\n",
    "\n",
    "    # max_lambd check to see\n",
    "    assert check_lamb(config=config, lamb=lamb), \"There seem to be a \" +\\\n",
    "        \"incoherence between bipartite source/targets and multiplex names\" +\\\n",
    "        \"provided in get_classic_grn_lamb\"\n",
    "\n",
    "    if draw is True:\n",
    "        to_draw_lamb = lamb.loc[[tf_multiplex, peak_multiplex, rna_multiplex],\n",
    "                                [tf_multiplex, peak_multiplex, rna_multiplex]]\n",
    "        draw_lamb(to_draw_lamb)\n",
    "\n",
    "    return lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f32bc46-8187-454a-afa5-cb97799d429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_layer_eta(config, starting_multiplex='RNA'):\n",
    "\n",
    "    ordered_multiplex = config['multiplex'].keys()\n",
    "    assert rna_multiplex in ordered_multiplex, \"It seems rna_multiplex not \" +\\\n",
    "        \"in config['multiplex']\"\n",
    "\n",
    "    eta = [0 if multiplex != starting_multiplex else 1\n",
    "           for multiplex in ordered_multiplex]\n",
    "\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622556ab-612f-4a0b-bd89-79e90fc74325",
   "metadata": {},
   "outputs": [],
   "source": [
    "hummuspy.config.get_target_genes_lamb(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b6042-823c-42f4-a1a4-081bffe78b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7714731-13f0-4dff-b535-12c39879c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d2372e-c319-465b-abec-507c209e0197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hummuspy.explore_network\n",
    "import hummuspy.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c131f82d-21d9-4d64-96a9-bb8f06ffa11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hummuspy.explore_network.define_grn_from_config('a', config, njobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4ea878e-6e75-412d-a6a5-3ca2f47d5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hummuspy.explore_network import *\n",
    "def get_output_from_dicts(\n",
    "        output_request: Union['grn', 'enhancers', 'binding_regions', 'target_genes'],\n",
    "        multilayer_f,\n",
    "        multiplexes_list,\n",
    "        bipartites_list,\n",
    "        folder_multiplexes='multiplex',\n",
    "        folder_bipartites='bipartite',\n",
    "        gene_list=None,\n",
    "        tf_list=None,\n",
    "        config_filename='grn_hummuspy.config.yml',\n",
    "        config_folder='config',\n",
    "        tf_multiplex: str = 'TF',\n",
    "        peak_multiplex: str = 'peaks',\n",
    "        rna_multiplex: str = 'RNA',\n",
    "        update_config=True,\n",
    "        save=False,\n",
    "        return_df=True,\n",
    "        output_f=None,\n",
    "        njobs=1):\n",
    "    \"\"\"Define a GRN from a multilayer network and a config file.\n",
    "    Random walks are computed for each gene in the gene list and we keep\n",
    "    the probability to reach each TF in the TF list.\n",
    "    You can provide a list of genes and TFs to restrict the GRN.\n",
    "    You can choose to save the result in a file and/or return it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    multilayer_f : str\n",
    "        Path to the multilayer folder.\n",
    "    config : dict\n",
    "        Config dictionnary.\n",
    "    gene_list : list, optional\n",
    "        List of genes. The default is 'all'.\n",
    "    tf_list : list, optional\n",
    "        List of TFs. The default is 'all'.\n",
    "    config_name : str, optional\n",
    "        Name of the config file. The default is 'grn_hummuspy.config.yml'.\n",
    "    config_folder : str, optional\n",
    "        Name of the config folder. The default is 'config'.\n",
    "    tf_multiplex : str, optional\n",
    "        Name of the TF multiplex. The default is 'TF'.\n",
    "    peak_multiplex : str, optional\n",
    "        Name of the peak multiplex. The default is 'peaks'.\n",
    "    rna_multiplex : str, optional\n",
    "        Name of the RNA multiplex. The default is 'RNA'.\n",
    "    update_config : bool, optional\n",
    "        Update the config file. The default is True.\n",
    "    save : bool, optional\n",
    "        Save the result. The default is False.\n",
    "    return_df : bool, optional\n",
    "        Return the result. The default is True.\n",
    "    output_f : str, optional\n",
    "        Name of the output file. The default is None.\n",
    "    njobs : int, optional\n",
    "        Number of jobs. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing the random walks's results that defines the GRN.\n",
    "        Columns:\n",
    "            layer : str\n",
    "                Name of the target layer.\n",
    "\n",
    "            path_layer : str\n",
    "                Name of the layer of the path.\n",
    "            score : float\n",
    "                Score of the random walk.\n",
    "            gene : str\n",
    "                Name of the gene-seed.\n",
    "            tf : str\n",
    "                Name of the TF-target.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    njobs = int(njobs)\n",
    "    print('multiplexes_list : ', multiplexes_list)\n",
    "    print('bipartites_list : ', bipartites_list)\n",
    "    print('folder_multiplexes : ', folder_multiplexes)\n",
    "    print('folder_bipartites : ', folder_bipartites)\n",
    "    print('gene_list : ', gene_list)\n",
    "    print('tf_list : ', tf_list)\n",
    "    print('config_filename : ', config_filename)\n",
    "    print('config_folder : ', config_folder)\n",
    "    print('tf_multiplex : ', tf_multiplex)\n",
    "    print('peak_multiplex : ', peak_multiplex)\n",
    "    print('rna_multiplex : ', rna_multiplex)\n",
    "    print('update_config : ', update_config)\n",
    "    print('save : ', save)\n",
    "    print('return_df : ', return_df)\n",
    "    print('output_f : ', output_f)\n",
    "    print('njobs : ', njobs)\n",
    "\n",
    "    # Create general config file\n",
    "    config = hummuspy.config.general_config(\n",
    "        multiplexes=multiplexes_list,\n",
    "        bipartites=bipartites_list,\n",
    "        folder_multiplexes=folder_multiplexes,\n",
    "        folder_bipartites=folder_bipartites,\n",
    "        suffix='.tsv',\n",
    "        self_loops=0,\n",
    "        restart_prob=0.7,\n",
    "        bipartites_type=('00', '00'),\n",
    "        save_configfile=False,\n",
    "        config_filename=config_filename)\n",
    "\n",
    "    parameters = {\n",
    "        'multilayer_f':   multilayer_f,\n",
    "        'config':         config,\n",
    "        'gene_list':      gene_list,\n",
    "        'tf_list':        tf_list,\n",
    "        'config_name':    config_filename,\n",
    "        'config_folder':  config_folder,\n",
    "        'tf_multiplex':   tf_multiplex,\n",
    "        'peak_multiplex': peak_multiplex,\n",
    "        'rna_multiplex':  rna_multiplex,\n",
    "        'update_config':  update_config,\n",
    "        'save':           save,\n",
    "        'return_df':      return_df,\n",
    "        'output_f':       output_f,\n",
    "        'njobs':          njobs\n",
    "    }\n",
    "    \n",
    "    if output_request == 'grn':\n",
    "        df = define_grn_from_config(**parameters)\n",
    "        \n",
    "    elif output_request == 'enhancers':\n",
    "        df = define_enhancers_from_config(**parameters)\n",
    "\n",
    "    elif output_request == 'binding_regions':\n",
    "        df = define_binding_regions_from_config(**parameters)\n",
    "\n",
    "    elif output_request == 'target_genes':\n",
    "        df = define_target_genes_from_config(**parameters)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8450381b-1617-4d51-b0b5-0b288ec61f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_values_list(\n",
    "        values,\n",
    "        types: Union[str, bool, int, float] = (str, bool, int, float)):\n",
    "    \"\"\"Transform layer type to be sure a list of values is returned.\n",
    "    Parameters\n",
    "    ----------\n",
    "    values: list, dict, str, bool, int, float\n",
    "        The values to transform into a list.\n",
    "    types: list, dict, str, bool, int, float\n",
    "        The types of the values to transform into a list.\n",
    "    Returns\n",
    "    -------\n",
    "    values: list\n",
    "        The values transformed into a list.\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError if the values are not of the given types.\n",
    "\n",
    "    \"\"\"\n",
    "    types = list(types)\n",
    "    if type(values) == list:\n",
    "        return values\n",
    "    elif type(values) == tuple:\n",
    "        return list(values)\n",
    "    elif type(values) == dict:\n",
    "        return list(values.values())\n",
    "    elif type(values) in types:\n",
    "        return [values]\n",
    "    else:\n",
    "        raise TypeError('Layer name(s) {} should be given through {},'.format(\n",
    "            values,\n",
    "            types) +\n",
    "            'a list, or a dictionary(where the key would be the file_paths)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d75947ae-f7a9-4176-ba7c-d195b6addfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23ac6721-b89a-4301-acf4-5548039debe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplex_list = {'TF': {'TF_network': '00'}, 'RNA': {'RNA_GENIE3': '00'}, 'peaks': {'peak_network_cicero': '00'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d72b9e5-a32f-48f6-9e5d-abcee12792a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartites_list = {'atac_rna.tsv' : {'multiplex_right' : 'RNA', 'multiplex_left' : 'peaks'}, \n",
    "                   'tf_peak.tsv' : {'multiplex_right' : 'TF', 'multiplex_left' : 'peaks'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0321f18e-f253-44c6-86a3-ad0d6ab1a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_output_from_dicts('grn', \n",
    "                      'b',\n",
    "                      multiplexes_list=multiplex_list,\n",
    "                      bipartites_list=bipartites_list,\n",
    "                     njobs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1fe5b4a-723a-4d32-9257-bc7f3ca1b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3a47fa-896b-48e4-b8cd-08d92141bb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'hummuspy.explore_network',\n",
       " '__doc__': None,\n",
       " '__package__': 'hummuspy',\n",
       " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x7fcbf45c1240>,\n",
       " '__spec__': ModuleSpec(name='hummuspy.explore_network', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7fcbf45c1240>, origin='/home/rtrimbou/miniconda3/lib/python3.10/site-packages/hummuspy/explore_network.py'),\n",
       " '__file__': '/home/rtrimbou/miniconda3/lib/python3.10/site-packages/hummuspy/explore_network.py',\n",
       " '__cached__': '/home/rtrimbou/miniconda3/lib/python3.10/site-packages/hummuspy/__pycache__/explore_network.cpython-310.pyc',\n",
       " '__builtins__': {'__name__': 'builtins',\n",
       "  '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "  '__package__': '',\n",
       "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "  '__build_class__': <function __build_class__>,\n",
       "  '__import__': <function __import__>,\n",
       "  'abs': <function abs(x, /)>,\n",
       "  'all': <function all(iterable, /)>,\n",
       "  'any': <function any(iterable, /)>,\n",
       "  'ascii': <function ascii(obj, /)>,\n",
       "  'bin': <function bin(number, /)>,\n",
       "  'breakpoint': <function breakpoint>,\n",
       "  'callable': <function callable(obj, /)>,\n",
       "  'chr': <function chr(i, /)>,\n",
       "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "  'delattr': <function delattr(obj, name, /)>,\n",
       "  'dir': <function dir>,\n",
       "  'divmod': <function divmod(x, y, /)>,\n",
       "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "  'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "  'format': <function format(value, format_spec='', /)>,\n",
       "  'getattr': <function getattr>,\n",
       "  'globals': <function globals()>,\n",
       "  'hasattr': <function hasattr(obj, name, /)>,\n",
       "  'hash': <function hash(obj, /)>,\n",
       "  'hex': <function hex(number, /)>,\n",
       "  'id': <function id(obj, /)>,\n",
       "  'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fcbf7f1a560>>,\n",
       "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "  'iter': <function iter>,\n",
       "  'aiter': <function aiter(async_iterable, /)>,\n",
       "  'len': <function len(obj, /)>,\n",
       "  'locals': <function locals()>,\n",
       "  'max': <function max>,\n",
       "  'min': <function min>,\n",
       "  'next': <function next>,\n",
       "  'anext': <function anext>,\n",
       "  'oct': <function oct(number, /)>,\n",
       "  'ord': <function ord(c, /)>,\n",
       "  'pow': <function pow(base, exp, mod=None)>,\n",
       "  'print': <function print>,\n",
       "  'repr': <function repr(obj, /)>,\n",
       "  'round': <function round(number, ndigits=None)>,\n",
       "  'setattr': <function setattr(obj, name, value, /)>,\n",
       "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "  'sum': <function sum(iterable, /, start=0)>,\n",
       "  'vars': <function vars>,\n",
       "  'None': None,\n",
       "  'Ellipsis': Ellipsis,\n",
       "  'NotImplemented': NotImplemented,\n",
       "  'False': False,\n",
       "  'True': True,\n",
       "  'bool': bool,\n",
       "  'memoryview': memoryview,\n",
       "  'bytearray': bytearray,\n",
       "  'bytes': bytes,\n",
       "  'classmethod': classmethod,\n",
       "  'complex': complex,\n",
       "  'dict': dict,\n",
       "  'enumerate': enumerate,\n",
       "  'filter': filter,\n",
       "  'float': float,\n",
       "  'frozenset': frozenset,\n",
       "  'property': property,\n",
       "  'int': int,\n",
       "  'list': list,\n",
       "  'map': map,\n",
       "  'object': object,\n",
       "  'range': range,\n",
       "  'reversed': reversed,\n",
       "  'set': set,\n",
       "  'slice': slice,\n",
       "  'staticmethod': staticmethod,\n",
       "  'str': str,\n",
       "  'super': super,\n",
       "  'tuple': tuple,\n",
       "  'type': type,\n",
       "  'zip': zip,\n",
       "  '__debug__': True,\n",
       "  'BaseException': BaseException,\n",
       "  'Exception': Exception,\n",
       "  'TypeError': TypeError,\n",
       "  'StopAsyncIteration': StopAsyncIteration,\n",
       "  'StopIteration': StopIteration,\n",
       "  'GeneratorExit': GeneratorExit,\n",
       "  'SystemExit': SystemExit,\n",
       "  'KeyboardInterrupt': KeyboardInterrupt,\n",
       "  'ImportError': ImportError,\n",
       "  'ModuleNotFoundError': ModuleNotFoundError,\n",
       "  'OSError': OSError,\n",
       "  'EnvironmentError': OSError,\n",
       "  'IOError': OSError,\n",
       "  'EOFError': EOFError,\n",
       "  'RuntimeError': RuntimeError,\n",
       "  'RecursionError': RecursionError,\n",
       "  'NotImplementedError': NotImplementedError,\n",
       "  'NameError': NameError,\n",
       "  'UnboundLocalError': UnboundLocalError,\n",
       "  'AttributeError': AttributeError,\n",
       "  'SyntaxError': SyntaxError,\n",
       "  'IndentationError': IndentationError,\n",
       "  'TabError': TabError,\n",
       "  'LookupError': LookupError,\n",
       "  'IndexError': IndexError,\n",
       "  'KeyError': KeyError,\n",
       "  'ValueError': ValueError,\n",
       "  'UnicodeError': UnicodeError,\n",
       "  'UnicodeEncodeError': UnicodeEncodeError,\n",
       "  'UnicodeDecodeError': UnicodeDecodeError,\n",
       "  'UnicodeTranslateError': UnicodeTranslateError,\n",
       "  'AssertionError': AssertionError,\n",
       "  'ArithmeticError': ArithmeticError,\n",
       "  'FloatingPointError': FloatingPointError,\n",
       "  'OverflowError': OverflowError,\n",
       "  'ZeroDivisionError': ZeroDivisionError,\n",
       "  'SystemError': SystemError,\n",
       "  'ReferenceError': ReferenceError,\n",
       "  'MemoryError': MemoryError,\n",
       "  'BufferError': BufferError,\n",
       "  'Warning': Warning,\n",
       "  'UserWarning': UserWarning,\n",
       "  'EncodingWarning': EncodingWarning,\n",
       "  'DeprecationWarning': DeprecationWarning,\n",
       "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "  'SyntaxWarning': SyntaxWarning,\n",
       "  'RuntimeWarning': RuntimeWarning,\n",
       "  'FutureWarning': FutureWarning,\n",
       "  'ImportWarning': ImportWarning,\n",
       "  'UnicodeWarning': UnicodeWarning,\n",
       "  'BytesWarning': BytesWarning,\n",
       "  'ResourceWarning': ResourceWarning,\n",
       "  'ConnectionError': ConnectionError,\n",
       "  'BlockingIOError': BlockingIOError,\n",
       "  'BrokenPipeError': BrokenPipeError,\n",
       "  'ChildProcessError': ChildProcessError,\n",
       "  'ConnectionAbortedError': ConnectionAbortedError,\n",
       "  'ConnectionRefusedError': ConnectionRefusedError,\n",
       "  'ConnectionResetError': ConnectionResetError,\n",
       "  'FileExistsError': FileExistsError,\n",
       "  'FileNotFoundError': FileNotFoundError,\n",
       "  'IsADirectoryError': IsADirectoryError,\n",
       "  'NotADirectoryError': NotADirectoryError,\n",
       "  'InterruptedError': InterruptedError,\n",
       "  'PermissionError': PermissionError,\n",
       "  'ProcessLookupError': ProcessLookupError,\n",
       "  'TimeoutError': TimeoutError,\n",
       "  'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "  'copyright': Copyright (c) 2001-2022 Python Software Foundation.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 2000 BeOpen.com.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "  All Rights Reserved.,\n",
       "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "      for supporting Python development.  See www.python.org for more information.,\n",
       "  'license': Type license() to see the full license text,\n",
       "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "  'execfile': <function _pydev_imps._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "  'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "  '__IPYTHON__': True,\n",
       "  'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "  '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1014__': <capsule object NULL at 0x7fcb98f37b10>,\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fcbf7f65210>>},\n",
       " 'yaml': <module 'yaml' from '/home/rtrimbou/miniconda3/lib/python3.10/site-packages/yaml/__init__.py'>,\n",
       " 'np': <module 'numpy' from '/home/rtrimbou/miniconda3/lib/python3.10/site-packages/numpy/__init__.py'>,\n",
       " 'pd': <module 'pandas' from '/home/rtrimbou/miniconda3/lib/python3.10/site-packages/pandas/__init__.py'>,\n",
       " 'mxr': <module 'multixrank' from '/home/rtrimbou/miniconda3/lib/python3.10/site-packages/multixrank/__init__.py'>,\n",
       " 'Parallel': joblib.parallel.Parallel,\n",
       " 'delayed': <function joblib.parallel.delayed(function)>,\n",
       " 'tqdm': tqdm.std.tqdm,\n",
       " 'Union': typing.Union,\n",
       " 'hummuspy': <module 'hummuspy' from '/home/rtrimbou/miniconda3/lib/python3.10/site-packages/hummuspy/__init__.py'>,\n",
       " 'compute_multiple_RandomWalk': <function hummuspy.explore_network.compute_multiple_RandomWalk(multilayer_f, config_name, output_f, list_seeds, config_folder='config', save=True, return_df=False, spec_layer_result_saved='all', njobs=1)>,\n",
       " 'compute_RandomWalk': <function hummuspy.explore_network.compute_RandomWalk(multilayer_f, config_name, seeds, config_folder='config', spec_layer_result_saved='all', unnamed=False, njobs=1)>,\n",
       " 'define_grn_from_config': <function hummuspy.explore_network.define_grn_from_config(multilayer_f, config, gene_list=None, tf_list=None, config_name='grn_hummuspy.config.yml', config_folder='config', tf_multiplex: str = 'TF', peak_multiplex: str = 'peaks', rna_multiplex: str = 'RNA', update_config=True, save=False, return_df=True, output_f=None, njobs=1)>,\n",
       " 'define_enhancers_from_config': <function hummuspy.explore_network.define_enhancers_from_config(multilayer_f, config, gene_list=None, peak_list=None, config_name='grn_hummuspy.config.yml', config_folder='config', tf_multiplex: str = 'TF', peak_multiplex: str = 'peaks', rna_multiplex: str = 'RNA', update_config=True, save=False, return_df=True, output_f=None, njobs=1)>,\n",
       " 'define_binding_regions_from_config': <function hummuspy.explore_network.define_binding_regions_from_config(multilayer_f, config, tf_list=None, peak_list=None, config_name='grn_hummuspy.config.yml', config_folder='config', tf_multiplex: str = 'TF', peak_multiplex: str = 'peaks', rna_multiplex: str = 'RNA', update_config=True, save=False, return_df=True, output_f=None, njobs=1)>,\n",
       " 'define_target_genes_from_config': <function hummuspy.explore_network.define_target_genes_from_config(multilayer_f, config, gene_list=None, tf_list=None, config_name='grn_hummuspy.config.yml', config_folder='config', tf_multiplex: str = 'TF', peak_multiplex: str = 'peaks', rna_multiplex: str = 'RNA', update_config=True, save=False, return_df=True, output_f=None, njobs=1)>,\n",
       " 'get_output_from_dicts': <function hummuspy.explore_network.get_output_from_dicts(output_request: Union[ForwardRef('grn'), ForwardRef('enhancers'), ForwardRef('binding_regions'), ForwardRef('target_genes')], multilayer_f, multiplexes_list, bipartites_list, folder_multiplexes='multiplex', folder_bipartites='bipartite', gene_list=None, tf_list=None, config_filename='grn_hummuspy.config.yml', config_folder='config', tf_multiplex: str = 'TF', peak_multiplex: str = 'peaks', rna_multiplex: str = 'RNA', update_config=True, save=False, return_df=True, output_f=None, njobs=1)>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hummuspy.explore_network.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073d918-1536-4159-9205-4f50f51ae49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
